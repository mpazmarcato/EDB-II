\subsection{Análise do Algoritmo Iterativo}

O algoritmo Quick Sort utiliza a estratégia de divisão e conquista, selecionando um pivô e particionando o array ao redor desse pivô, de modo que os elementos menores que o pivô fiquem à esquerda e os maiores à direita. A complexidade do Quick Sort varia conforme a escolha do pivô.

\subsubsection{Melhor caso: \(\Omega(n \log n)\)}
No melhor caso, o pivô divide o array em duas partes aproximadamente iguais em cada iteração. Assim, a profundidade da recursão é logarítmica e, em cada nível da recursão, são feitas \(n\) comparações para particionar o array. A complexidade pode ser expressa por algo como:
\[
f(n) = n \log n + 3
\]
Onde \(n \log n\) representa as comparações, e \(3\) é a constante \(c\) que representa operações que não dependem da entrada, como a escolha do pivô e outras operações fixas. Calculamos o limite:

\[
\lim_{n \to \infty} \frac{f(n)}{n \log n} = \lim_{n \to \infty} \frac{n \log n + 3}{n \log n}
\]

Isso se simplifica para:

\[
= \lim_{n \to \infty} \left(1 + \frac{3}{n \log n}\right) = 1 + 0 = 1
\]

Assim, a complexidade do melhor caso é \(\Omega(n \log n)\).

\subsubsection{Pior caso: \(O(n^2)\)}
No pior caso, o pivô escolhido é o menor ou o maior elemento, o que resulta em uma partição altamente desequilibrada, onde um dos subarrays é vazio e o outro contém todos os elementos restantes. Nesse cenário, o Quick Sort se degrada para uma estrutura semelhante à de um algoritmo de ordenação por seleção, executando \(n\) comparações em cada nível da recursão, com uma profundidade de recursão de \(n\). A complexidade pode ser expressa como:
\[
h(n) = n^2 + 5
\]
Onde \(5\) é a constante \(d\), representando operações fixas que não dependem da entrada. Calculamos o limite:

\[
\lim_{n \to \infty} \frac{h(n)}{n^2} = \lim_{n \to \infty} \frac{n^2 + 5}{n^2}
\]

Isso se simplifica para:

\[
= \lim_{n \to \infty} \left(1 + \frac{5}{n^2}\right) = 1 + 0 = 1
\]

Assim, a complexidade do pior caso é \(O(n^2)\).

\subsubsection{Conclusão}
\begin{itemize}
  \item Melhor caso: \(\Omega(n \log n)\)
  \item Pior caso: \(O(n^2)\)
\end{itemize}

Portanto, a algoritmo tem pior caso \(O(n^2)\), melhor caso \(\Omega(n \log n)\) e não há $\Theta$.
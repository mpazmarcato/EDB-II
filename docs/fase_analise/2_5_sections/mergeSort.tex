\subsubsection{Análise do Algoritmo Mergesort} 

\hspace{0.6cm}O Mergesort é um algoritmo de ordenação eficiente, especialmente adequado para conjuntos de dados grandes. Para conjuntos com menos de mil elementos, o tempo de execução é quase imperceptível (1 ms), devido à sua eficiência e ao baixo impacto da sobrecarga nas chamadas de função. Isso torna ambas as versões (recursiva e iterativa) competitivas, já que a quantidade de elementos é pequena e o tempo de ordenação é insignificante em hardware moderno.

Para conjuntos acima de 100 mil elementos, ambas as versões (recursiva e iterativa) apresentam um desempenho similar, levando aproximadamente 58 ms para concluir a ordenação. Essa equivalência de tempo ocorre porque, embora a versão iterativa evite a sobrecarga das chamadas recursivas, a complexidade de ambas continua sendo \(O(n \log n)\). Assim, o ganho de desempenho esperado na versão iterativa não se traduz em uma diferença significativa de tempo de execução em conjuntos grandes, provavelmente devido a otimizações no gerenciamento de memória e no uso da CPU, que minimizam o impacto da pilha de chamadas na versão recursiva.

Em termos de complexidade, o Mergesort possui uma complexidade de tempo de \(O(n \log n)\) tanto para o pior caso quanto para o melhor e o caso médio, pois o algoritmo divide a lista em duas metades recursivamente (\(\log n\) divisões), e cada divisão requer \(O(n)\) tempo para mesclar as sublistas ordenadas.

Para conjuntos pequenos, o desempenho entre as versões é praticamente idêntico. Já para conjuntos grandes, embora a versão iterativa pudesse teoricamente ser mais eficiente, na prática ambas se equiparam em tempo de execução. Dessa forma, essa análise mostra que, em geral, ambas as versões podem ser usadas de forma intercambiável para conjuntos de dados extensos, e a escolha pode ser feita com base em fatores secundários, como a preferência por estrutura de código ou limitação de memória.
